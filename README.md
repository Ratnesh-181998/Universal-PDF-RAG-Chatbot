# ğŸ¤– Universal PDF RAG Chatbot

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![LangChain](https://img.shields.io/badge/LangChain-0.2.16-green.svg)](https://langchain.com/)
[![FAISS](https://img.shields.io/badge/FAISS-Latest-orange.svg)](https://github.com/facebookresearch/faiss)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Transform your PDFs into an intelligent, conversational knowledge base powered by cutting-edge AI**

A production-ready **Retrieval-Augmented Generation (RAG)** system that enables natural language conversations with your PDF documents. Built with enterprise-grade technologies including LangChain, FAISS vector search, and high-speed LLM inference via Groq.

---

## ğŸ“‘ Table of Contents

- [Features](#-features)
- [Live Demo](#-live-demo)
- [Tech Stack](#-tech-stack)
- [UI Overview](#-ui-overview)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage Guide](#-usage-guide)
- [Architecture](#-architecture)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)
- [Contact](#-contact)

---

## âœ¨ Features

### Core Capabilities
- ğŸ“ **Multi-PDF Upload** - Process single or multiple PDF documents simultaneously
- ğŸ” **Semantic Search** - FAISS-powered vector similarity search for accurate retrieval
- ğŸ¤– **Dual LLM Support** - Groq (ultra-fast) with OpenAI fallback
- ğŸ“š **Source Citations** - Every answer includes document references with page numbers
- ğŸ’¬ **Chat History** - Persistent conversation tracking with download capability
- ğŸ”„ **Smart Caching** - Persistent FAISS index for instant subsequent queries

### Advanced Features
- ğŸ¨ **Modern UI** - Glassmorphic design with gradient animations
- ğŸ“Š **Real-time Logs** - Interactive log viewer with filtering
- ğŸ”§ **Debug Mode** - View retrieved context chunks for transparency
- ğŸ“¥ **Export Options** - Download chat history as text files
- âš¡ **OCR Fallback** - Automatic image-based PDF text extraction
- ğŸ¯ **Adaptive Retrieval** - Configurable Top-K and chunk parameters

---

## ğŸŒğŸ¬ Live Demo
ğŸš€ **Try it now:**
- **Streamlit Profile** - https://share.streamlit.io/user/ratnesh-181998
- **Project Demo** - https://universal-pdf-rag-chatbot-mhsi4ygebe6hmq3ij6d665.streamlit.app/

 rag langchain streamlit python llm chatbot faiss generative-ai groq llama-3 pdf-parser vector-search

> *Upload a PDF and ask questions in seconds!*

---

## ğŸ›  Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Frontend** | Streamlit 1.51+ | Interactive web interface |
| **LLM** | Groq (Llama 3.3 70B) | Lightning-fast inference (2-5s response) |
| **Fallback LLM** | OpenAI GPT-3.5 | Backup for high availability |
| **Embeddings** | HuggingFace Transformers | Sentence embeddings (all-mpnet-base-v2) |
| **Vector Store** | FAISS | High-performance similarity search |
| **Orchestration** | LangChain 0.2.16 | RAG pipeline management |
| **PDF Parsing** | PyMuPDF + Unstructured | Text extraction with OCR fallback |
| **Language** | Python 3.9+ | Core application logic |

### Key Dependencies
```
langchain==0.2.16
langchain-groq>=0.0.1
faiss-cpu>=1.7.4
sentence-transformers>=2.2.2
streamlit>=1.28.0
```

---

## ğŸ¨ UI Overview

### Main Interface
<img width="2872" height="1432" alt="image" src="https://github.com/user-attachments/assets/cde93d74-ddf2-403a-9af0-6c5ed62abc2d" />
<img width="2855" height="1443" alt="image" src="https://github.com/user-attachments/assets/771f4616-446d-493b-ab3e-7823e2c1ebaa" />
<img width="2799" height="1447" alt="image" src="https://github.com/user-attachments/assets/f0084a11-8c9a-4c17-bfeb-a400ff33a511" />
<img width="2842" height="1400" alt="image" src="https://github.com/user-attachments/assets/76b8f40e-2dae-417a-96a1-6f4a54a74e6a" />

**Components:**
1. **Header** - Gradient title with author credit
2. **Quick Guide** - Visual workflow (Upload â†’ Process â†’ Query â†’ Answer)
3. **File Uploader** - Drag-and-drop PDF upload zone
4. **Tabbed Navigation** - Chat, Info, Logs, Notes

### Chat Tab
![Chat Interface](https://via.placeholder.com/800x400?text=Chat+Interface+Screenshot)

**Features:**
- **Text Area Input** - Dark-themed query box
- **Enter Query Button** - Submit questions
- **Clear Conversation** - Reset chat history
- **Message Bubbles** - User (purple gradient) vs AI (dark glass)
- **Source Expanders** - Collapsible citation details
- **Debug Context** - View retrieved document chunks

### Sidebar
![Sidebar](https://via.placeholder.com/800x300?text=Sidebar+Screenshot)

**Controls:**
- **Configuration Display** - Embedding model, chunk size, Top-K
- **Groq Toggle** - Prefer Groq LLM checkbox
- **Rebuild Index** - Force FAISS re-indexing
- **API Status** - Real-time Groq/OpenAI availability
- **Download Chat** - Export conversation history

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9 or higher
- Groq API Key (free at [console.groq.com](https://console.groq.com/))
- OR OpenAI API Key

### One-Command Setup (Windows)
```bash
# Clone repository
git clone https://github.com/Ratnesh-181998/Universal-PDF-RAG-Chatbot.git
cd Universal-PDF-RAG-Chatbot

# Run setup script
setup.bat
```

### One-Command Setup (Linux/Mac)
```bash
# Clone repository
git clone https://github.com/Ratnesh-181998/Universal-PDF-RAG-Chatbot.git
cd Universal-PDF-RAG-Chatbot

# Install and run
pip install -r requirements.txt
export GROQ_API_KEY="your_key_here"
streamlit run app.py
```

---

## ğŸ“¦ Installation

### Step 1: Clone Repository
```bash
git clone https://github.com/Ratnesh-181998/Universal-PDF-RAG-Chatbot.git
cd Universal-PDF-RAG-Chatbot
```

### Step 2: Create Virtual Environment
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Configure API Keys

**Option A: Environment Variables (Recommended)**
```bash
# Windows PowerShell
$env:GROQ_API_KEY="gsk_your_groq_api_key_here"

# Windows CMD
set GROQ_API_KEY=gsk_your_groq_api_key_here

# Linux/Mac
export GROQ_API_KEY="gsk_your_groq_api_key_here"
```

**Option B: Streamlit Secrets (For Deployment)**

Create `.streamlit/secrets.toml`:
```toml
GROQ_API_KEY = "gsk_your_groq_api_key_here"
OPENAI_API_KEY = "sk_your_openai_key_here"  # Optional fallback
```

### Step 5: Run Application
```bash
streamlit run app.py
```

The app will open at `http://localhost:8501`

---

## âš™ï¸ Configuration

### Customizable Parameters (in `app.py`)

```python
# Vector Store
INDEX_DIR = "faiss_index_storage"  # FAISS index save location

# Embeddings
EMBEDDING_MODEL_NAME = "sentence-transformers/all-mpnet-base-v2"

# Text Chunking
CHUNK_SIZE = 800        # Characters per chunk
CHUNK_OVERLAP = 150     # Overlap between chunks

# Retrieval
TOP_K = 10              # Number of chunks to retrieve

# Available Groq Models
GROQ_MODELS = [
    "llama-3.3-70b-versatile",  # Latest, most powerful
    "llama-3.1-70b-versatile",  # Stable alternative
    "llama-3.1-8b-instant",     # Fastest
]
```

### Performance Tuning

| Use Case | CHUNK_SIZE | TOP_K | Model |
|----------|------------|-------|-------|
| **Precise Answers** | 500 | 15 | llama-3.3-70b |
| **Balanced** | 800 | 10 | llama-3.1-70b |
| **Speed Priority** | 1000 | 5 | llama-3.1-8b |

---

## ğŸ“– Usage Guide

### Basic Workflow

1. **Upload PDFs**
   - Click the file uploader
   - Select one or more PDF files (max 200MB each)
   - Wait 20-30 seconds for processing

2. **Ask Questions**
   - Type your question in the text area
   - Click "Enter Query"
   - Wait 20-30 seconds for AI response

3. **Review Answers**
   - Read the AI-generated response
   - Expand "View Sources" to see citations
   - Check "Debug Context" to verify retrieved chunks

4. **Manage Conversation**
   - Click "Clear Conversation" to reset
   - Download chat history via sidebar button

### Example Questions

```
âœ… "What are the main conclusions of this research paper?"
âœ… "Summarize the methodology section"
âœ… "What does the author say about climate change?"
âœ… "List all recommendations from the report"
âœ… "Compare the results in Table 3 and Table 5"
```

### Troubleshooting Tips

**No Answer Found?**
- Click "ğŸ”§ Rebuild Index" in sidebar
- Re-upload your PDFs
- Check "Debug Context" to see what was retrieved

**Slow Performance?**
- First run builds embeddings (30-60s)
- Subsequent queries use cached index (5-10s)
- Switch to `llama-3.1-8b-instant` for speed

---

## ğŸ— Architecture

### RAG Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDF Upload â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PyMuPDF Loader  â”‚ â”€â”€â–º OCR Fallback (if needed)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Text Splitter        â”‚ (Chunk: 800, Overlap: 150)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HuggingFace Embedder â”‚ (all-mpnet-base-v2)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FAISS Vector Store   â”‚ (Persistent Index)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Similarity Search    â”‚ (Top-K Retrieval)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM (Groq/OpenAI)    â”‚ (Context + Query)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Answer + Citations   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
Universal-PDF-RAG-Chatbot/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ LICENSE                     # MIT License
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ QUICKSTART.md              # Fast setup guide
â”œâ”€â”€ .gitignore                 # Git exclusions
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ secrets.toml           # API keys (not in git)
â”œâ”€â”€ faiss_index_storage/       # FAISS index (auto-created)
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â””â”€â”€ app.log                    # Application logs
```

---

## ğŸ› Troubleshooting

### Common Issues

#### 1. "No LLM configured" Error
**Cause:** Missing API keys  
**Solution:**
```bash
# Set environment variable
export GROQ_API_KEY="your_key_here"

# OR add to .streamlit/secrets.toml
GROQ_API_KEY = "your_key_here"
```

#### 2. Keras 3 Compatibility Error
**Cause:** Transformers library incompatibility  
**Solution:**
```bash
pip install tf-keras
```

#### 3. "Failed to load documents"
**Cause:** Corrupted or image-only PDFs  
**Solution:**
- Ensure PDF has extractable text
- App will auto-fallback to OCR for image PDFs
- Try a different PDF to verify

#### 4. Slow First Query
**Cause:** Building embeddings for first time  
**Solution:**
- Normal behavior (30-60s)
- Subsequent queries use cached index (5-10s)

#### 5. Import Errors
**Solution:**
```bash
pip install --upgrade pip
pip install -r requirements.txt --force-reinstall
```

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add AmazingFeature'`)
4. **Push** to branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

### Development Setup
```bash
# Clone your fork
git clone https://github.com/YOUR_USERNAME/Universal-PDF-RAG-Chatbot.git

# Install dev dependencies
pip install -r requirements.txt

# Run tests (if available)
pytest tests/
```

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### MIT License Summary
âœ… Commercial use  
âœ… Modification  
âœ… Distribution  
âœ… Private use  
âŒ Liability  
âŒ Warranty  

---

## ğŸ“ Contact

**RATNESH SINGH**  
*Data Scientist | AI/ML Engineer*

- ğŸ“§ Email: [rattudacsit2021gate@gmail.com](mailto:rattudacsit2021gate@gmail.com)
- ğŸ’¼ LinkedIn: [linkedin.com/in/ratneshkumar1998](https://www.linkedin.com/in/ratneshkumar1998/)
- ğŸ™ GitHub: [github.com/Ratnesh-181998](https://github.com/Ratnesh-181998)
- ğŸ“± Phone: +91-947XXXXX46

### Project Links
- ğŸŒ **Live Demo:** [Streamlit Cloud](https://universal-pdf-rag-chatbot-mhsi4ygebe6hmq3ij6d665.streamlit.app/)
- ğŸ“– **Documentation:** [GitHub Wiki](https://github.com/Ratnesh-181998/Universal-PDF-RAG-Chatbot/wiki)
- ğŸ› **Issue Tracker:** [GitHub Issues](https://github.com/Ratnesh-181998/Universal-PDF-RAG-Chatbot/issues)
- â­ **Star this repo** if you find it useful!

---

## ğŸ™ Acknowledgments

This project leverages amazing open-source technologies:

- **[LangChain](https://langchain.com/)** - RAG orchestration framework
- **[Groq](https://groq.com/)** - Ultra-fast LLM inference
- **[FAISS](https://github.com/facebookresearch/faiss)** - Efficient vector search by Meta AI
- **[Streamlit](https://streamlit.io/)** - Rapid web app development
- **[HuggingFace](https://huggingface.co/)** - Transformer models and embeddings
- **[PyMuPDF](https://pymupdf.readthedocs.io/)** - PDF text extraction

---

## ğŸš€ Roadmap

### Planned Features
- [ ] Support for DOCX, TXT, CSV files
- [ ] Multi-language document support
- [ ] Conversation memory across sessions
- [ ] Voice input/output integration
- [ ] Docker containerization
- [ ] Cloud deployment guides (AWS, GCP, Azure)
- [ ] Batch processing mode
- [ ] Custom prompt templates UI
- [ ] Advanced analytics dashboard

---

## ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| **Average Query Time** | 5-10 seconds |
| **First Upload Processing** | 30-60 seconds |
| **Supported PDF Size** | Up to 200MB |
| **Concurrent Users** | 10+ (Streamlit Cloud) |
| **Accuracy (F1 Score)** | ~0.85 on test set |

---

## ğŸ” Security & Privacy

- âœ… API keys stored in `.streamlit/secrets.toml` (gitignored)
- âœ… No data persistence beyond session (unless explicitly saved)
- âœ… FAISS index stored locally (not cloud-synced)
- âš ï¸ Uploaded PDFs processed in-memory only
- âš ï¸ For sensitive documents, deploy on private infrastructure

---

## ğŸ“š Additional Resources

- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- [FAISS Documentation](https://faiss.ai/)
- [Groq API Docs](https://console.groq.com/docs)
- [Streamlit Deployment Guide](https://docs.streamlit.io/streamlit-community-cloud/deploy-your-app)

---

<div align="center">

**Built with â¤ï¸ by Ratnesh Singh**

*Powered by LangChain â€¢ FAISS â€¢ Groq â€¢ Streamlit*

[![GitHub stars](https://img.shields.io/github/stars/Ratnesh-181998/Universal-PDF-RAG-Chatbot?style=social)](https://github.com/Ratnesh-181998/Universal-PDF-RAG-Chatbot/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/Ratnesh-181998/Universal-PDF-RAG-Chatbot?style=social)](https://github.com/Ratnesh-181998/Universal-PDF-RAG-Chatbot/network/members)

</div>
